{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502a333a-27f7-4144-a169-44e30bb0f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\n"
     ]
    }
   ],
   "source": [
    "seeds = list(range(1000, 1 * 2000, 1000))\n",
    "print(seeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886dd85b-b0fd-4184-9f0f-6eeccba64636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing, time\n",
    "\n",
    "def print_squares(number):\n",
    "    for i in range(number):\n",
    "        print(\"square of {0} is {1}\".format(i , i*i))\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def print_cubes(number):\n",
    "    for j in range(number):\n",
    "        print(\"cube of {0} is {1}\".format(j, j*j*j))\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826827ec-6a43-4518-ae3f-95a4cd4b221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square of 0 is 0\n",
      "cube of 0 is 0\n",
      "square of 1 is 1\n",
      "cube of 1 is 1\n",
      "square of 2 is 4\n",
      "cube of 2 is 8\n",
      "square of 3 is 9\n",
      "cube of 3 is 27\n",
      "square of 4 is 16\n",
      "cube of 4 is 64\n",
      "square of 5 is 25\n",
      "cube of 5 is 125\n",
      "square of 6 is 36\n",
      "cube of 6 is 216\n",
      "square of 7 is 49\n",
      "cube of 7 is 343\n",
      "square of 8 is 64\n",
      "cube of 8 is 512\n",
      "square of 9 is 81\n",
      "cube of 9 is 729\n"
     ]
    }
   ],
   "source": [
    "process_1 = multiprocessing.Process(target = print_squares, args = (10,))\n",
    "process_2 = multiprocessing.Process(target = print_cubes, args = (10,))\n",
    "\n",
    "process_1.start()\n",
    "process_2.start()\n",
    "\n",
    "process_1.join()\n",
    "process_2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1cd776f-bb4a-4ad7-95d4-606ca1ac1c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "detla = float('-inf')\n",
    "if 1e-7 > detla:\n",
    "    print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58a68ef0-135a-4cb5-9db2-927facc9ad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 50, 768])\n",
      "torch.Size([50, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([5, 50]) torch.Size([5, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand((5,50,768))\n",
    "b = torch.rand((5,50,768))\n",
    "\n",
    "print(a.shape)\n",
    "c = torch.cosine_similarity(a,b, dim=0)\n",
    "d = torch.cosine_similarity(a,b, dim=1)\n",
    "e = torch.cosine_similarity(a,b, dim=-1)\n",
    "a_ = a[:,0,:]\n",
    "b_ = b[:,0,:]\n",
    "f = torch.cosine_similarity(a_,b_, dim=1)\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "print(e.shape, (1 - e).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c96b175-a23d-4673-87ce-0bbf60b170e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 7\n"
     ]
    }
   ],
   "source": [
    "t = 10\n",
    "print(t % 7, t - t % 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbf80375-8bf4-4a00-8f32-1d395a088ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "t = 8\n",
    "x = t % 7\n",
    "y = t // 7\n",
    "print(x, y)\n",
    "# print(t % 7, t - (t / 7 - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aaf2ab3c-1fb4-42bf-90b1-14866f3682f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 49, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.randn(5, 3, 224, 224)\n",
    "kernel_h = 32\n",
    "kernel_w = 32\n",
    "step = 32\n",
    "n_channels = 3\n",
    "patches = x.unfold(2, kernel_h, step).unfold(3, kernel_w, step).reshape(-1, n_channels, 49, 32, 32)#.permute(2, 3, 0, 1, 4, 5).reshape(-1, n_channels, kernel_h, kernel_w)\n",
    "\n",
    "print(patches.shape)\n",
    "\n",
    "# patches = x.unfold(1, kc, dc).unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "# unfold_shape = patches.size()\n",
    "# patches = patches.contiguous().view(-1, kc, kh, kw)\n",
    "# print(patches.shape)\n",
    "\n",
    "# # Reshape back\n",
    "# patches_orig = patches.view(unfold_shape)\n",
    "# output_c = unfold_shape[1] * unfold_shape[4]\n",
    "# output_h = unfold_shape[2] * unfold_shape[5]\n",
    "# output_w = unfold_shape[3] * unfold_shape[6]\n",
    "# patches_orig = patches_orig.permute(0, 1, 4, 2, 5, 3, 6).contiguous()\n",
    "# patches_orig = patches_orig.view(1, output_c, output_h, output_w)\n",
    "\n",
    "# # Check for equality\n",
    "# print((patches_orig == x[:, :output_c, :output_h, :output_w]).all())\n",
    "# # > tensor(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d92c45a-442d-49e2-b14f-e338f08be23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 284, 143, 143)\n",
    "kc, kh, kw = 128, 128, 128  # kernel size\n",
    "dc, dh, dw = 128, 128, 128  # stride\n",
    "# Pad to multiples of 128\n",
    "# x = F.pad(x, (x.size(2)%kw // 2, x.size(2)%kw // 2,\n",
    "#               x.size(1)%kh // 2, x.size(1)%kh // 2,\n",
    "#               x.size(0)%kc // 2, x.size(0)%kc // 2))\n",
    "\n",
    "\n",
    "patches = x.unfold(1, kc, dc).unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "unfold_shape = patches.size()\n",
    "patches = patches.contiguous().view(-1, kc, kh, kw)\n",
    "print(patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a4fd66a-18bc-46f0-93c2-ffb81cf5526f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5807516\n",
      "4194304\n"
     ]
    }
   ],
   "source": [
    "print(1 * 284 * 143 * 143)\n",
    "print(2 * 128 * 128 * 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a12fc7e1-1d77-4f31-b96a-5b2b0bd06e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((10,10)).cuda()\n",
    "print(x.shape)\n",
    "y = x.clone()\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c2187-1823-4da2-81c4-5ee00ea4b2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbf39c4b-a23f-44ea-b53a-6f0e41d1e856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:epoch: 0, mini_loss: 3.0, kloss: 0.0\n",
      "INFO:root:epoch: 1, mini_loss: 3.0, kloss: 0.0\n",
      "INFO:root:epoch: 2, mini_loss: 4.0, kloss: 0.0\n",
      "INFO:root:epoch: 3, mini_loss: 3.0, kloss: 0.0\n",
      "INFO:root:epoch: 4, mini_loss: 3.0, kloss: 0.0\n",
      "INFO:root:epoch: 5, mini_loss: 6.0, kloss: 0.0\n",
      "INFO:root:epoch: 6, mini_loss: 6.0, kloss: 0.0\n",
      "INFO:root:epoch: 7, mini_loss: 1.0, kloss: 0.0\n",
      "INFO:root:epoch: 8, mini_loss: 5.0, kloss: 0.0\n",
      "INFO:root:epoch: 9, mini_loss: 5.0, kloss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.9000],\n",
      "       requires_grad=True)\n",
      "tensor([ 1.8626e-09, -9.3132e-10,  1.8626e-09,  9.3132e-10,  5.5879e-09,\n",
      "         9.3132e-10,  8.9000e-01], requires_grad=True)\n",
      "tensor([-0.0091, -0.0100, -0.0100, -0.0097, -0.0079, -0.0093,  0.8823],\n",
      "       requires_grad=True)\n",
      "tensor([-0.0187, -0.0185, -0.0182, -0.0185, -0.0167, -0.0169,  0.8739],\n",
      "       requires_grad=True)\n",
      "tensor([-0.0279, -0.0275, -0.0270, -0.0275, -0.0259, -0.0254,  0.8648],\n",
      "       requires_grad=True)\n",
      "tensor([-0.0370, -0.0365, -0.0363, -0.0369, -0.0353, -0.0344,  0.8555],\n",
      "       requires_grad=True)\n",
      "tensor([-0.0463, -0.0452, -0.0458, -0.0465, -0.0442, -0.0425,  0.8461],\n",
      "       requires_grad=True)\n",
      "tensor([-0.0559, -0.0540, -0.0549, -0.0550, -0.0534, -0.0497,  0.8374],\n",
      "       requires_grad=True)\n",
      "tensor([-0.0657, -0.0623, -0.0634, -0.0629, -0.0622, -0.0576,  0.8292],\n",
      "       requires_grad=True)\n",
      "tensor([-0.0756, -0.0709, -0.0723, -0.0714, -0.0712, -0.0660,  0.8204],\n",
      "       requires_grad=True)\n",
      "tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "\n",
    "\n",
    "def test_gumble_softmax():\n",
    "    logging.basicConfig(level=\"INFO\")\n",
    "    mask = torch.rand(5)\n",
    "    k = 3\n",
    "    mask = torch.tensor([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.9])\n",
    "    mask.requires_grad = True\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-2, betas=(0.9, 0.999))\n",
    "    for step in range(10):\n",
    "        optimizer.zero_grad()\n",
    "        mask_new = torch.sigmoid(mask)\n",
    "        mask_flipped = 1 - mask_new\n",
    "        # print(\"new\", mask_new)\n",
    "        # print(\"flip\", mask_flipped)\n",
    "        v = torch.stack((torch.log(mask_new), torch.log(mask_flipped)), dim=-1)\n",
    "        # print(\"v\", v)\n",
    "        hard_mask = torch.nn.functional.gumbel_softmax(v, 0.8, True)\n",
    "        # print(hard_mask)\n",
    "        mini_loss = torch.sum(hard_mask[:, 0])  # minimal sum\n",
    "        k_loss = 0 * (torch.sum(hard_mask[:, 0]) - k) ** 2  # choose only k values\n",
    "        loss = k_loss + mini_loss\n",
    "        logging.info('epoch: {}, mini_loss: {}, kloss: {}'.format(step, mini_loss.item(), k_loss.item()))\n",
    "        print(mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    assert k - 20 <= mini_loss.item() <= k + 20\n",
    "    print(hard_mask)\n",
    "test_gumble_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9ac27-d6a0-4a09-8649-4e5df998cfa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44a4d7b-81d0-481d-8725-15ca9eb681da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "torch.Size([5, 768])\n",
      "tensor(3840.)\n"
     ]
    }
   ],
   "source": [
    "# 5, 50, 768\n",
    "import torch\n",
    "a = torch.ones((5, 50, 768))\n",
    "a[:, 0, :] = 0\n",
    "print(a[:, 0, :].sum())\n",
    "print(a[:, 0, :].shape)\n",
    "print(a[:, 1, :].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d61fb-b935-4e0b-94d8-2cdaa9399294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
