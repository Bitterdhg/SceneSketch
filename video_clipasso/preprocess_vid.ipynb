{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cbb38e-198f-44ea-ba1d-7b8ed2d745df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Proprocess of an input video\n",
    "### At the moment this scripts only supports the creation of three subfolders containing: (1) the frames (2) masks for each frame (3) the masked object for each frame\n",
    "### We need to add another folder containing (4) the inpainted background for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0789b005-08ad-4ef9-af3b-f0df5bf517ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to your own paths .....\n",
    "path_to_videos_input = \"/home/vinker/dev/input_images/videos_input\"\n",
    "path_to_output_frames = \"/home/vinker/dev/input_images/videos_input/frames\"\n",
    "unet_dir = \"/home/vinker/dev/backgroundCLIPasso/CLIPasso/U2Net_/saved_models/u2net.pth\"\n",
    "# the name of the video you want to process\n",
    "video_filename = \"horse_vid.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eb76296-b967-4010-92d6-bf3eb58ce81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pylab\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys \n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import PIL\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "p = os.path.abspath('..')\n",
    "sys.path.insert(1, p)\n",
    "import sketch_utils as sketch_utils\n",
    "from U2Net_.model import U2NET\n",
    "import u2net_utils\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (\n",
    "            torch.cuda.is_available() and torch.cuda.device_count() > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5e44278-84c7-4af6-9e65-be2ea4ea5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = f\"{path_to_videos_input}/{video_filename}\"\n",
    "video_name = os.path.splitext(video_filename)[0]\n",
    "frames_res_dir = f\"{path_to_output_frames}/{video_name}\"\n",
    "if not os.path.isdir(frames_res_dir):\n",
    "    os.mkdir(frames_res_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801d092-5de4-4456-b00c-fa04f7affda0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79d8acb6-998c-48d2-8a85-9825a2c1a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, frames_output_dir, rescale_frames=1, start_frame=137, end_frame=140, display_frames=1):\n",
    "    # Notes: \n",
    "    # (1) This spesific script also cut the frames to be squared. Its better to insert a square video, and then change the flag \"rescale_frames\"\n",
    "    # (2) Some videos ar every long, so here we only take the frames from \"start_frame\" to \"end_frame\". change this according to your video\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Reading video from [{video_path}] ...\")\n",
    "    print(f\"Saving frames number [{start_frame}-{end_frame}] to [{frames_output_dir}]\")\n",
    "    if rescale_frames:\n",
    "        print(\"Applying rescale to the video\")\n",
    "    vid = imageio.get_reader(video_path,  'ffmpeg')\n",
    "    for frame_index, image in enumerate(vid):\n",
    "        if frame_index > end_frame:\n",
    "            break\n",
    "        elif frame_index > start_frame:\n",
    "            if rescale_frames:\n",
    "                height, width = image.shape[0], image.shape[1]\n",
    "                max_, min_ = max(height, width), min(height, width)\n",
    "                if width > height:     \n",
    "                    image = image[:, (max_ - min_) // 2: (max_ - min_) // 2 + min_]\n",
    "                else:\n",
    "                    image = image[(max_ - min_) // 2: (max_ - min_) // 2 + min_, :,: ]\n",
    "            if display_frames:\n",
    "                plt.imshow(image)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "            imageio.imsave(f\"{frames_output_dir}/{frame_index:03d}.png\", image)\n",
    "\n",
    "def create_output_dirs(frames_output_dir_top):\n",
    "    # for each video, we want to extract its frames, the mask for each frame, the masked object, and the inpainted background\n",
    "    if not os.path.isdir(frames_output_dir_top):\n",
    "        os.mkdir(frames_output_dir_top)\n",
    "    subdirs = [\"scene\", \"masks\", \"object\", \"background\"]\n",
    "    for dirname in subdirs:\n",
    "        if not os.path.isdir(f\"{frames_output_dir_top}/{dirname}\"):\n",
    "            os.mkdir(f\"{frames_output_dir_top}/{dirname}\")\n",
    "    print(f\"Your frames will be saved to [{frames_output_dir_top}]\")\n",
    "\n",
    "    \n",
    "def extract_masks(scene_frames_dir, output_masks_path, output_object_path, use_gpu=1, display_frames=1):\n",
    "    model_dir = os.path.join(unet_dir)\n",
    "    net = U2NET(3, 1)\n",
    "    if torch.cuda.is_available() and use_gpu:\n",
    "        net.load_state_dict(torch.load(model_dir))\n",
    "        net.to(device)\n",
    "    else:\n",
    "        net.load_state_dict(torch.load(model_dir, map_location='cpu'))\n",
    "    net.eval()\n",
    "    \n",
    "    for frame_i in os.listdir(scene_frames_dir):\n",
    "        frame_path = f\"{scene_frames_dir}/{frame_i}\"\n",
    "        frame = Image.open(frame_path).convert(\"RGB\")\n",
    "        if display_frames:\n",
    "            plt.imshow(frame)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "        w, h = frame.size[0], frame.size[1]\n",
    "        test_salobj_dataset = u2net_utils.SalObjDataset(imgs_list=[frame],\n",
    "                                                        lbl_name_list=[],\n",
    "                                                        transform=transforms.Compose([u2net_utils.RescaleT(320),\n",
    "                                                                                      u2net_utils.ToTensorLab(flag=0)]))\n",
    "        test_salobj_dataloader = DataLoader(test_salobj_dataset,\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=1)\n",
    "        input_im_trans = next(iter(test_salobj_dataloader))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input_im_trans = input_im_trans.type(torch.FloatTensor)\n",
    "            d1, d2, d3, d4, d5, d6, d7 = net(input_im_trans.to(device))\n",
    "        pred = d1[:, 0, :, :]\n",
    "        pred = (pred - pred.min()) / (pred.max() - pred.min())\n",
    "        predict = pred\n",
    "        predict[predict < 0.5] = 0\n",
    "        predict[predict >= 0.5] = 1\n",
    "\n",
    "        mask = torch.cat([predict, predict, predict], axis=0).permute(1, 2, 0)\n",
    "        mask = mask.cpu().numpy()\n",
    "        mask = resize(mask, (h, w), anti_aliasing=False)\n",
    "        mask[mask < 0.5] = 0\n",
    "        mask[mask >= 0.5] = 1\n",
    "        \n",
    "        imageio.imsave(f\"{output_masks_path}/{frame_i}\", mask)\n",
    "        if display_frames:\n",
    "            plt.imshow(mask)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "        frame_np = np.array(frame)\n",
    "        frame_np = frame_np / frame_np.max()\n",
    "        masked_obg = mask * frame_np\n",
    "        masked_obg[mask == 0] = 1\n",
    "        masked_obg = (masked_obg / masked_obg.max() * 255).astype(np.uint8)\n",
    "        masked_obg = Image.fromarray(masked_obg)\n",
    "        \n",
    "        imageio.imsave(f\"{output_object_path}/{frame_i}\", masked_obg)\n",
    "        if display_frames:\n",
    "            plt.imshow(masked_obg)\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab1b1c-59b2-468e-863d-1afad0c0690e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Run the entire preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45ec11d4-0f7a-44e6-bb45-ba9eecc395d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Reading video from [/home/vinker/dev/input_images/videos_input/horse_vid.mp4] ...\n",
      "Saving frames number [137-140] to [/home/vinker/dev/input_images/videos_input/frames/horse_vid/scene]\n",
      "Applying rescale to the video\n",
      "Your frames will be saved to [/home/vinker/dev/input_images/videos_input/frames/horse_vid]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "display_frames = False\n",
    "extract_frames(video_path, f\"{frames_res_dir}/scene\", rescale_frames=1, start_frame=137, end_frame=140, display_frames=display_frames)\n",
    "create_output_dirs(frames_res_dir)\n",
    "extract_masks(f\"{frames_res_dir}/scene\", f\"{frames_res_dir}/masks\", f\"{frames_res_dir}/object\", display_frames=display_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f908e86-6cef-4f32-84cd-e4459181bf89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
